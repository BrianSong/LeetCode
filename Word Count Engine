Word Count Engine
Implement a document scanning function wordCountEngine, which receives a string document and returns a list of all unique words in it 
and their number of occurrences, sorted by the number of occurrences in a descending order. 
If two or more words have the same count, they should be sorted according to their order in the original sentence. 
Assume that all letters are in english alphabet. You function should be case-insensitive, so for instance, 
the words “Perfect” and “perfect” should be considered the same word.

The engine should strip out punctuation (even in the middle of a word) and use whitespaces to separate words.

Analyze the time and space complexities of your solution. Try to optimize for time while keeping a polynomial space complexity.

Examples:

input:  document = "Practice makes perfect. you'll only
                    get Perfect by practice. just practice!"

output: [ ["practice", "3"], ["perfect", "2"],
          ["makes", "1"], ["youll", "1"], ["only", "1"], 
          ["get", "1"], ["by", "1"], ["just", "1"] ]
Important: please convert the occurrence integers in the output list to strings (e.g. "3" instead of 3). 
We ask this because in compiled languages such as C#, Java, C++, C etc., it’s not straightforward to create mixed-type arrays 
(as it is, for instance, in scripted languages like JavaScript, Python, Ruby etc.). 
The expected output will simply be an array of string arrays.

Constraints:

[time limit] 5000ms
[input] string document
[output] array.array.string

Solution: --------------------------------------------- O(N) T and S where N is the number of words
import collections

def word_count_engine(document):
      # Check the edge cases
      if not document:
        return ""
      # Use split() to get the individual words
      unprocess = document.split(" ")
      # Loop over my unprocess to process each individual words
      processed = []
      for item in unprocess:
        item = item.lower()
        processed_string = ""
        for c in item:
          if c.isalpha():
            processed_string += c
        if processed_string != "":
          processed.append(processed_string)
      # The trickey part of the question is that we need to output the individual words in two priority levels 
      # (frequency and original order in the input document)
      counter = collections.Counter(processed)
      max_freq = max(counter.values())
      # How to record the frequency while remain the same order? We cannot use a HashTable since it is unordered, 
      # then, we can use a list of list whose index is the frequency and the individual list stores all the elements 
      # that has the same frequency, and by append them into the individual list using the original order from processed, 
      # the order is also reserved
      word_of_same_freq = [[] for i in range(max_freq)]
      for item in processed:
        word_of_same_freq[counter[item] - 1].append(item)
      # visited here is to remove duplicate since we want O(1) look up
      visited = set()
      res = []
      for words in word_of_same_freq[::-1]:
        for word in words:
          if not word in visited:
            res.append([word, str(counter[word])])
            visited.add(word)
      return res
